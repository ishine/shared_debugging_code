train:
  seed: 1234
  epochs: 100
  batch_size: 12
  gradient_accumulation: 4
  save_every_n_epoch: 20
  precision: 32
  gradient_clip: 1.0
optimizer:
  lr: 0.0002
  lr_init: 0.000001
  lr_end: 0.00001
  warmup_steps: 2000
  decay_steps: 40000
data:
  train_metadata_path: 'data/ljspeech'
  train_semantic_token_path: 'data/ljspeech/km_semtok/ljspeech_0_1.km'
  eval_metadata_path: 'data/ljspeech'
  eval_semantic_token_path: 'data/ljspeech/km_semtok/ljspeech_0_1.km'
  max_eval_sample: 8
model:
  embedding_dim: 1024
  dim: 1024
  head: 16
  linear_units: 2048
  n_layer: 12
  semantic_codebook_size: 1025
  acoustic_codebook_size: 1025
  acoustic_num_quantizers: 8
  positionwise_conv_kernel_size: 1
  conv_module_kernel_size: 5
  hubert_kmean_path: 'data/ljspeech/kmeans_model'
inference:
    inference_steps: [8, 1, 1, 1, 1, 1, 1, 1]
    filter_threshold: 0.7
    temperature: 0.5
