train:
  seed: 1234
  epochs: 100
  batch_size: 12
  gradient_accumulation: 4
  save_every_n_epoch: 20
  precision: 32
  gradient_clip: 1.0
optimizer:
  lr: 0.01
  lr_init: 0.00001
  lr_end: 0.0001
  warmup_steps: 2000
  decay_steps: 40000
data:
  train_metadata_path: 'data/ljspeech'
  train_semantic_token_path: 'data/ljspeech/km_semtok/ljspeech_0_1.km'
  eval_metadata_path: 'data/ljspeech'
  eval_semantic_token_path: 'data/ljspeech/km_semtok/ljspeech_0_1.km'
  max_eval_sample: 8
model:
  vocab_size: 1025
  phoneme_vocab_size: 512
  embedding_dim: 512
  hidden_dim: 512
  head: 8
  linear_units: 2048
  n_layer: 12
  dropout: 0
  EOS: 1024
inference:
  top_k: -100
